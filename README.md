# AI_TutorM

Male-voiced AI Tutor Interface for the project:  Are AIs Gender Neutral? A Replication Study

## Final Report
https://docs.google.com/document/d/1ENj9euX4jAaj7BBArWIKf4ASWd3WEz0YaTgXzEnayU8/edit?usp=sharing

Abstract: Nass et al. (1997) studied if interaction with machines generated gender-based stereotypic responses in subjects, even if gender cues are minimal and irrelevant. This study looks at how people would apply gender stereotypes during interactions with computers, even with minimal gender cues (i.e. voice). The findings contribute to the research on people’s attitudes towards computers as social agents. The original experiment examined and confirmed three stereotypes. For this replication study, we focus on testing the hypothesis that confirmed the third stereotype: female-voiced computers are perceived as more knowledgeable on stereotypically feminine topics, while male computers are perceived as more knowledgeable on stereotypically masculine topics (Nass et al., 1997). In the original experiment, participants engaged with computer tutors that used either male or female voices. These computers played pre-recorded, CD-quality human voices reading standardized scripts. In our study, we plan to use pre-recorded voices generated from AI assistants to deliver standardized prompts. Participants will interact with a mock AI interface we designed, and they will be informed that it operates through an AI agent. We would like to see if the findings from the original experiment can be replicated in the interaction with AI agents that are more sophisticated and widely integrated into daily life nowadays.

## Original Study

Nass, C., Moon, Y., & Green, N. (1997). Are Machines Gender Neutral? Gender-Stereotypic Responses to Computers With Voices. Journal of Applied Social Psychology, 27(10), 864–876. https://doi.org/10.1111/j.1559-1816.1997.tb00275.x
